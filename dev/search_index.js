var documenterSearchIndex = {"docs":
[{"location":"lib/computing_nash_equilibria.html#computing_nash_equilibria","page":"Computing Nash Equilibria","title":"Computing Nash Equilibria","text":"","category":"section"},{"location":"lib/computing_nash_equilibria.html#Exported","page":"Computing Nash Equilibria","title":"Exported","text":"","category":"section"},{"location":"lib/computing_nash_equilibria.html#GameTheory.pure_nash-Tuple{NormalFormGame}","page":"Computing Nash Equilibria","title":"GameTheory.pure_nash","text":"pure_nash(nfg; ntofind=Inf, tol=1e-8)\n\nFinds all pure action Nash equilibria for a normal form game. It returns an empty array if there is no pure action Nash.\n\nCurrently uses a brute force algorithm, but that hopefully will change in the future.\n\nArguments\n\nnfg::NormalFormGame: Instance of N-player NormalFormGame.\nntofind::Inf: Maximal number of pure action Nash equilibria to be found; default is prod(nfg.nums_actions).\ntol::Real : Tolerance to be used to determine best response actions.\n\nReturns\n\nne::Vector{NTuple{N,Int}}: Vector of pure action Nash equilibria.\n\n\n\n\n\n","category":"method"},{"location":"lib/computing_nash_equilibria.html#GameTheory.support_enumeration-Union{Tuple{NormalFormGame{2, T}}, Tuple{T}} where T","page":"Computing Nash Equilibria","title":"GameTheory.support_enumeration","text":"support_enumeration(g)\n\nCompute mixed-action Nash equilibria with equal support size for a 2-player normal form game by support enumeration. For a non-degenerate game input, these are all the Nash equilibria.\n\nThe algorithm checks all the equal-size support pairs; if the players have the same number n of actions, there are 2n choose n minus 1 such pairs. This should thus be used only for small games.\n\nArguments\n\ng::NormalFormGame{2,T}: 2-player NormalFormGame instance.\n\nReturns\n\n::Vector{NTuple{2,Vector{S}}}: Mixed-action Nash equilibria that are found, where S is Float if T is Int or Float, and Rational if T is Rational.\n\n\n\n\n\n","category":"method"},{"location":"lib/computing_nash_equilibria.html#GameTheory.support_enumeration_task-Tuple{Channel, NormalFormGame{2}}","page":"Computing Nash Equilibria","title":"GameTheory.support_enumeration_task","text":"support_enumeration_task(c, g)\n\nTask version of support_enumeration.\n\nArguments\n\nc::Channel: Channel to be binded with the support enumeration task.\ng::NormalFormGame{2}: 2-player NormalFormGame instance.\n\nReturns\n\n::Task: Runnable task for generating Nash equilibria.\n\n\n\n\n\n","category":"method"},{"location":"lib/computing_nash_equilibria.html#GameTheory.lrsnash-Tuple{NormalFormGame{2, <:Union{Int64, Rational}}}","page":"Computing Nash Equilibria","title":"GameTheory.lrsnash","text":"lrsnash(g)\n\nCompute in exact arithmetic all extreme mixed-action Nash equilibria of a 2-player normal form game with Integer or Rational payoffs. This function calls the Nash equilibrium computation routine in lrslib (through its Julia wrapper LRSLib.jl) which is based on the \"lexicographic reverse search\" vertex enumeration algorithm.\n\nArguments\n\ng::NormalFormGame{2,<:RatOrInt}: 2-player NormalFormGame instance with Integer or Rational payoffs.\n\nReturns\n\n::Vector{NTuple{2,Vector{Rational{BigInt}}}}: Vector of mixed-action Nash equilibria.\n\nExamples\n\nA degenerate game example:\n\njulia> player1 = Player([3 3; 2 5; 0 6]);\n\njulia> player2 = Player([3 2 3; 3 6 1]);\n\njulia> g = NormalFormGame(player1, player2);\n\njulia> println(g)\n3×2 NormalFormGame{2, Int64}:\n [3, 3]  [3, 3]\n [2, 2]  [5, 6]\n [0, 3]  [6, 1]\n\njulia> lrsnash(g)\n3-element Vector{Tuple{Vector{Rational{BigInt}}, Vector{Rational{BigInt}}}}:\n ([1//1, 0//1, 0//1], [1//1, 0//1])\n ([1//1, 0//1, 0//1], [2//3, 1//3])\n ([0//1, 1//3, 2//3], [1//3, 2//3])\n\nThe set of Nash equilibria of this degenerate game consists of an isolated equilibrium, the third output, and a non-singleton equilibrium component, the extreme points of which are given by the first two outputs.\n\nReferences\n\nD. Avis, G. Rosenberg, R. Savani, and B. von Stengel, \"Enumeration of Nash Equilibria for Two-Player Games,\" Economic Theory (2010), 9-37.\n\n\n\n\n\n","category":"method"},{"location":"lib/computing_nash_equilibria.html#GameTheory.hc_solve-Union{Tuple{NormalFormGame{N}}, Tuple{N}} where N","page":"Computing Nash Equilibria","title":"GameTheory.hc_solve","text":"hc_solve(g; ntofind=Inf, options...)\n\nCompute all isolated mixed-action Nash equilibria of an N-player normal form game.\n\nThis function solves a system of polynomial equations arising from the nonlinear complementarity problem representation of Nash eqiulibrium, by using HomotopyContinuation.jl.\n\nArguments\n\ng::NormalFormGame: N-player NormalFormGame instance.\nntofind=Inf: Number of Nash equilibria to find.\noptions...: Optional arguments to pass to HomotopyContinuation.solve. For example, the option seed::UInt32 can set the random seed used during the computations. See the documentation for HomotopyContinuation.solve for details.\n\nReturns\n\n::Vector{NTuple{N,Vector{Float64}}}: Vector of mixed-action Nash equilibria.\n\nExamples\n\nConsider the 3-player 2-action game with 9 Nash equilibria in McKelvey and McLennan (1996) \"Computation of Equilibria in Finite Games\":\n\njulia> Base.active_repl.options.iocontext[:compact] = true;  # Reduce digits to display\n\njulia> g = NormalFormGame((2, 2, 2));\n\njulia> g[1, 1, 1] = [9, 8, 12];\n\njulia> g[2, 2, 1] = [9, 8, 2];\n\njulia> g[1, 2, 2] = [3, 4, 6];\n\njulia> g[2, 1, 2] = [3, 4, 4];\n\njulia> println(g)\n2×2×2 NormalFormGame{3, Float64}:\n[:, :, 1] =\n [9.0, 8.0, 12.0]  [0.0, 0.0, 0.0]\n [0.0, 0.0, 0.0]   [9.0, 8.0, 2.0]\n\n[:, :, 2] =\n [0.0, 0.0, 0.0]  [3.0, 4.0, 6.0]\n [3.0, 4.0, 4.0]  [0.0, 0.0, 0.0]\n\njulia> NEs = hc_solve(g, show_progress=false)\n9-element Vector{Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}}}:\n ([0.0, 1.0], [0.333333, 0.666667], [0.333333, 0.666667])\n ([1.0, 0.0], [0.0, 1.0], [0.0, 1.0])\n ([0.25, 0.75], [0.5, 0.5], [0.333333, 0.666667])\n ([0.5, 0.5], [0.5, 0.5], [1.0, -7.34684e-40])\n ([0.0, 1.0], [1.0, 0.0], [-2.93874e-39, 1.0])\n ([0.0, 1.0], [0.0, 1.0], [1.0, 0.0])\n ([0.5, 0.5], [0.333333, 0.666667], [0.25, 0.75])\n ([1.0, 4.48416e-44], [1.0, -7.17465e-43], [1.0, -4.48416e-44])\n ([0.25, 0.75], [1.0, 0.0], [0.25, 0.75])\n\njulia> all([is_nash(g, NE) for NE in NEs])\ntrue\n\n\n\n\n\n","category":"method"},{"location":"lib/computing_nash_equilibria.html#Internal","page":"Computing Nash Equilibria","title":"Internal","text":"","category":"section"},{"location":"lib/computing_nash_equilibria.html#GameTheory._indiff_mixed_action!-Union{Tuple{T}, Tuple{Matrix{T}, Vector{T}, BitVector, Vector{T}, Matrix, Vector{Int64}, Vector{Int64}}} where T<:Real","page":"Computing Nash Equilibria","title":"GameTheory._indiff_mixed_action!","text":"_indiff_mixed_action!(A, b, own_supp_flags, out,\n                      payoff_matrix, own_supp, opp_supp)\n\nGiven a player's payoff matrix payoff_matrix, an array own_supp of this player's actions, and an array opp_supp of the opponent's actions, each of length k, compute the opponent's mixed action whose support equals opp_supp and for which the player is indifferent among the actions in own_supp, if any such exists. Return true if such a mixed action exists and actions in own_supp are indeed best responses to it, in which case the outcome is stored in out; false otherwise. Arrays A, b, own_supp_flags are used in intermediate steps.\n\nArguments\n\nA::Matrix{T}: Matrix of shape (k+1, k+1) used in intermediate steps, where T<:Real.\nb::Vector{T}: Vector of length k+1 used in intermediate steps, where T<:Real.\nown_supp_flags::BitVector: BitVector of length m used in intermediate steps.\nout::Vector{T}: Vector of length k to store the nonzero values of the desired mixed action, where T<:Real.\npayoff_matrix::Matrix: The player's payoff matrix, of shape (m, n).\nown_supp::Vector{Int}: Vector containing the player's action indices, of length k.\nopp_supp::Vector{Int}: Vector containing the opponent's action indices, of length k.\n\nReturns\n\n::Bool: true if a desired mixed action exists and false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"lib/computing_nash_equilibria.html#GameTheory._support_enumeration_producer-Union{Tuple{T}, Tuple{Channel, Tuple{Matrix{T}, Matrix{T}}}} where T<:Real","page":"Computing Nash Equilibria","title":"GameTheory._support_enumeration_producer","text":"_support_enumeration_producer(c, payoff_matrices)\n\nMain body of support_enumeration_task.\n\nArguments\n\nc::Channel: Channel to be binded with the support enumeration task.\npayoff_matrices::NTuple{2,Matrix{T}}: Payoff matrices of player 1 and player 2, where T<:Real.\n\nPuts\n\nNTuple{2,Vector{S}}: Tuple of Nash equilibrium mixed actions, where S is Float if T is Int or Float, and Rational if T is Rational.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#base_types_and_methods","page":"Base Types and Methods","title":"Base Types and Methods","text":"","category":"section"},{"location":"lib/base_types_and_methods.html#Exported","page":"Base Types and Methods","title":"Exported","text":"","category":"section"},{"location":"lib/base_types_and_methods.html#GameTheory.Action","page":"Base Types and Methods","title":"GameTheory.Action","text":"Action{T}\n\nAlias for Union{PureAction,MixedAction{T}} where T<:Real.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.ActionProfile","page":"Base Types and Methods","title":"GameTheory.ActionProfile","text":"ActionProfile{N,T}\n\nAlias for Union{PureActionProfile{N,T},MixedActionProfile{N,T}}.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.MixedAction","page":"Base Types and Methods","title":"GameTheory.MixedAction","text":"MixedAction{T}\n\nAlias for Vector{T} where T<:Real.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.MixedActionProfile","page":"Base Types and Methods","title":"GameTheory.MixedActionProfile","text":"MixedActionProfile{N,T}\n\nAlias for NTuple{N,MixedAction{T}} where T<:Real.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.PureAction","page":"Base Types and Methods","title":"GameTheory.PureAction","text":"PureAction\n\nAlias for Integer.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.PureActionProfile","page":"Base Types and Methods","title":"GameTheory.PureActionProfile","text":"PureActionProfile{N,T}\n\nAlias for NTuple{N,T} where T<:PureAction.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.BROptions","page":"Base Types and Methods","title":"GameTheory.BROptions","text":"BROptions\n\nStruct to contain options for best_response.\n\nFields\n\ntol::Real=1e-8 : Tolerance level.\ntie_breaking::Symbol=:smallest : :smallest or :random.\nrng::AbstractRNG=GLOBAL_RNG : Random number generator.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame{N,T}\n\nType representing an N-player normal form game.\n\nFields\n\nplayers::NTuple{N,Player{N,T<:Real}} : Tuple of Player instances.\nnums_actions::NTuple{N,Int} : Tuple of the numbers of actions, one for each player.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{Array{Player{N, T}, 1}}, Tuple{T}, Tuple{N}} where {N, T}","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(players)\n\nConstructor of an N-player NormalFormGame with a vector of N Player instances.\n\nArguments\n\nplayers::Vector{Player} : Vector of Player instances.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{Array{T, M}}, Tuple{M}, Tuple{T}} where {T<:Real, M}","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(payoffs)\n\nConstruct an N-player NormalFormGame for N>=2 with an array payoffs of M=N+1 dimensions, where payoffs[a_1, a_2, ..., a_N, :] contains a profile of N payoff values.\n\nArguments\n\npayoffs::Array{T<:Real} : Array with ndims=N+1 containing payoff profiles.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{Array{TV, N}}, Tuple{TV}, Tuple{N}, Tuple{T}} where {T<:Real, N, TV<:AbstractVector{T}}","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(payoffs)\n\nConstruct an N-player NormalFormGame with an N-dimensional array payoffs of vectors, where payoffs[a_1, a_2, ..., a_N] contains a vector of N payoff values, one for each player, for the action profile (a_1, a_2, ..., a_N).\n\nArguments\n\npayoffs::Array{AbstractVector{T<:Real}} : Array with ndims=N containing payoff profiles as vectors.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{Matrix{T}}, Tuple{T}} where T<:Real","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(payoffs)\n\nConstruct a symmetric 2-player NormalFormGame with a square matrix.\n\nArguments\n\npayoffs::Matrix{T<:Real} : Square matrix representing each player's payoff matrix.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{NTuple{N, Player{N, T}}}, Tuple{T}, Tuple{N}} where {N, T}","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(players)\n\nConstructor of an N-player NormalFormGame with a tuple of N Player instances.\n\nArguments\n\nplayers::NTuple{N,Player} : Tuple of Player instances.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{N}, Tuple{Type, NTuple{N, Int64}}} where N","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame([T=Float64], nums_actions)\n\nConstructor of an N-player NormalFormGame, consisting of payoffs all 0.\n\nArguments\n\nT::Type : Type of payoff values; defaults to Float64 if not specified.\nnums_actions::NTuple{N,Int} : Numbers of actions of the N players.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{N}, Tuple{T}, Tuple{Type{T}, NormalFormGame{N}}} where {T<:Real, N}","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(T, g)\n\nConvert g into a new NormalFormGame instance with eltype T.\n\nArguments\n\nT::Type\ng::NormalFormGame\n\nReturns\n\n::NormalFormGame : NormalFormGame instance with eltype T.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.NormalFormGame-Union{Tuple{Vararg{Player{N, T}}}, Tuple{T}, Tuple{N}} where {N, T}","page":"Base Types and Methods","title":"GameTheory.NormalFormGame","text":"NormalFormGame(players...)\n\nConstructor of an N-player NormalFormGame with N Player instances.\n\nArguments\n\nplayers::Player{N,T}... : N Player instances\n\nExamples\n\n# p1, p2, and p3 are all of type `Player{3,T}` for some `T`\nNormalFormGame(p1, p2, p3)\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.Player","page":"Base Types and Methods","title":"GameTheory.Player","text":"Player{N,T}\n\nType representing a player in an N-player normal form game.\n\nFields\n\npayoff_array::Array{T<:Real} : Array representing the player's payoff function.\n\n\n\n\n\n","category":"type"},{"location":"lib/base_types_and_methods.html#GameTheory.Player-Union{Tuple{N}, Tuple{T}, Tuple{Type{T}, Player{N}}} where {T<:Real, N}","page":"Base Types and Methods","title":"GameTheory.Player","text":"Player(T, player)\n\nConvert player into a new Player instance with eltype T.\n\nArguments\n\nT::Type\nplayer::Player\n\nReturns\n\n::Player : Player instance with eltype T.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.best_response-Tuple{Player, Union{Nothing, Integer, NTuple{N, T} where {N, T}, NTuple{N, Vector{T}} where {N, T}, Vector{T} where T<:Real}, BROptions}","page":"Base Types and Methods","title":"GameTheory.best_response","text":"best_response(player, opponents_actions, options)\n\nReturn a best response action to opponents_actions with options as specified by a BROptions instance options.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.best_response-Tuple{Player, Union{Nothing, Integer, NTuple{N, T} where {N, T}, NTuple{N, Vector{T}} where {N, T}, Vector{T} where T<:Real}, Vector{Float64}}","page":"Base Types and Methods","title":"GameTheory.best_response","text":"best_response(player, opponents_actions, payoff_perturbation)\n\nReturn the perturbed best response to opponents_actions.\n\nArguments\n\nplayer::Player : Player instance.\nopponents_actions::Union{Action,ActionProfile,Nothing} : Profile of N-1 opponents' actions. If N=2, then it must be a vector of reals (in which case it is treated as the opponent's mixed action) or a scalar of integer (in which case it is treated as the opponent's pure action). If N>2, then it must be a tuple of N-1 integers (pure actions) or N-1 vectors of reals (mixed actions). (For the degenerate case N=1, it must be nothing.)\npayoff_perturbation::Vector{Float64} : Vector of length equal to the number of actions of the player containing the values (\"noises\") to be added to the payoffs in determining the best response.\n\nReturns\n\n::Int : Best response action.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.best_response-Tuple{Random.AbstractRNG, Player, Union{Nothing, Integer, NTuple{N, T} where {N, T}, NTuple{N, Vector{T}} where {N, T}, Vector{T} where T<:Real}}","page":"Base Types and Methods","title":"GameTheory.best_response","text":"best_response([rng=GLOBAL_RNG], player, opponents_actions;\n              tie_breaking=:smallest, tol=1e-8)\n\nReturn a best response action to opponents_actions.\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG : Random number generator; relevant only with tie_breaking=:random.\nplayer::Player : Player instance.\nopponents_actions::Union{Action,ActionProfile,Nothing} : Profile of N-1 opponents' actions. If N=2, then it must be a vector of reals (in which case it is treated as the opponent's mixed action) or a scalar of integer (in which case it is treated as the opponent's pure action). If N>2, then it must be a tuple of N-1 integers (pure actions) or N-1 vectors of reals (mixed actions). (For the degenerate case N=1, it must be nothing.)\ntie_breaking::Symbol : Control how to break a tie (see Returns for details).\ntol::Real : Tolerance to be used to determine best response actions.\n\nReturns\n\n::Int : If tie_breaking=:smallest, returns the best response action with the smallest index; if tie_breaking=:random, returns an action randomly chosen from the best response actions.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.best_responses-Tuple{Player, Union{Nothing, Integer, NTuple{N, T} where {N, T}, NTuple{N, Vector{T}} where {N, T}, Vector{T} where T<:Real}}","page":"Base Types and Methods","title":"GameTheory.best_responses","text":"best_responses(player, opponents_actions; tol=1e-8)\n\nReturn all the best response actions to opponents_actions.\n\nArguments\n\nplayer::Player : Player instance.\nopponents_actions::Union{Action,ActionProfile,Nothing} : Profile of N-1 opponents' actions. If N=2, then it must be a vector of reals (in which case it is treated as the opponent's mixed action) or a scalar of integer (in which case it is treated as the opponent's pure action). If N>2, then it must be a tuple of N-1 integers (pure actions) or N-1 vectors of reals (mixed actions). (For the degenerate case N=1, it must be nothing.)\ntol::Real : Tolerance to be used to determine best response actions.\n\nReturns\n\nbest_responses::Vector{Int} : Vector containing all the best response actions.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.delete_action-Union{Tuple{N}, Tuple{NormalFormGame{N}, AbstractVector{<:Integer}, Integer}} where N","page":"Base Types and Methods","title":"GameTheory.delete_action","text":"delete_action(g, action, player_idx)\n\nReturn a new NormalFormGame instance with the action(s) specified by action deleted from the action set of the player specified by player_idx.\n\nArguments\n\ng::NormalFormGame : NormalFormGame instance.\naction::Union{PureAction, AbstractVector{<:PureAction}} : The action(s) to be deleted.\nplayer_idx::Integer : Index of the player to delete action(s) for.\n\nReturns\n\n::NormalFormGame : NormalFormGame instance with the action(s) deleted as specified.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.delete_action-Union{Tuple{T}, Tuple{N}, Tuple{Player{N, T}, AbstractVector{<:Integer}}, Tuple{Player{N, T}, AbstractVector{<:Integer}, Integer}} where {N, T}","page":"Base Types and Methods","title":"GameTheory.delete_action","text":"delete_action(player, action[, player_idx=1])\n\nReturn a new Player instance with the action(s) specified by action deleted from the action set of the player specified by player_idx.\n\nArguments\n\nplayer::Player : Player instance.\naction::Union{PureAction,AbstractVector{<:PureAction}}: The action(s) to be deleted.\nplayer_idx::Integer : Index of the player to delete action(s) for.\n\nReturns\n\n::Player : Player instance with the action(s) deleted as specified.\n\nExamples\n\njulia> player = Player([3 0; 0 3; 1 1])\n3×2 Player{2, Int64}:\n 3  0\n 0  3\n 1  1\n\njulia> delete_action(player, 3)\n2×2 Player{2, Int64}:\n 3  0\n 0  3\n\njulia> delete_action(player, 1, 2)\n3×1 Player{2, Int64}:\n 0\n 3\n 1\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.dominated_actions-Union{Tuple{T}, Tuple{Type{T}, Player}} where T<:Real","page":"Base Types and Methods","title":"GameTheory.dominated_actions","text":"dominated_actions(player; tol=1e-8,\n                  lp_solver=GameTheory.highs_optimizer_silent)\n\nReturn a vector of actions that are strictly dominated by some mixed actions.\n\nArguments\n\nplayer::Player : Player instance.\ntol::Real : Tolerance level used in determining domination.\nlp_solver::Union{Type{<:MathOptInterface.AbstractOptimizer},Function} : Linear programming solver to be used internally. Pass a MathOptInterface.AbstractOptimizer type (such as HiGHS.Optimizer) if no option is needed, or a function (such as GameTheory.highs_optimizer_silent) to supply options.\n\nReturns\n\nout::Vector{Int} : Vector of integers representing pure actions, each of which is strictly dominated by some mixed action.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.is_best_response-Tuple{Player, Integer, Union{Nothing, Integer, NTuple{N, T} where {N, T}, NTuple{N, Vector{T}} where {N, T}, Vector{T} where T<:Real}}","page":"Base Types and Methods","title":"GameTheory.is_best_response","text":"is_best_response(player, own_action, opponents_actions; tol=1e-8)\n\nReturn true if own_action is a best response to opponents_actions.\n\nArguments\n\nplayer::Player : Player instance.\nown_action::PureAction : Own pure action (integer).\nopponents_actions::Union{Action,ActionProfile,Nothing} : Profile of N-1 opponents' actions. If N=2, then it must be a vector of reals (in which case it is treated as the opponent's mixed action) or a scalar of integer (in which case it is treated as the opponent's pure action). If N>2, then it must be a tuple of N-1 integers (pure actions) or N-1 vectors of reals (mixed actions). (For the degenerate case N=1, it must be nothing.)\ntol::Real : Tolerance to be used to determine best response actions.\n\nReturns\n\n::Bool : True if own_action is a best response to opponents_actions; false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.is_best_response-Tuple{Player, Vector{T} where T<:Real, Union{Nothing, Integer, NTuple{N, T} where {N, T}, NTuple{N, Vector{T}} where {N, T}, Vector{T} where T<:Real}}","page":"Base Types and Methods","title":"GameTheory.is_best_response","text":"is_best_response(player, own_action, opponents_actions; tol=1e-8)\n\nReturn true if own_action is a best response to opponents_actions.\n\nArguments\n\nplayer::Player : Player instance.\nown_action::MixedAction : Own mixed action (vector of reals).\nopponents_actions::Union{Action,ActionProfile,Nothing} : Profile of N-1 opponents' actions. If N=2, then it must be a vector of reals (in which case it is treated as the opponent's mixed action) or a scalar of integer (in which case it is treated as the opponent's pure action). If N>2, then it must be a tuple of N-1 integers (pure actions) or N-1 vectors of reals (mixed actions). (For the degenerate case N=1, it must be nothing.)\ntol::Real : Tolerance to be used to determine best response actions.\n\nReturns\n\n::Bool : True if own_action is a best response to opponents_actions; false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.is_dominated-Union{Tuple{T}, Tuple{Type{T}, Player, Integer}} where T<:Real","page":"Base Types and Methods","title":"GameTheory.is_dominated","text":"is_dominated(player, action; tol=1e-8,\n             lp_solver=GameTheory.highs_optimizer_silent)\n\nDetermine whether action is strictly dominated by some mixed action.\n\nArguments\n\nplayer::Player : Player instance.\naction::PureAction : Integer representing a pure action.\ntol::Real : Tolerance level used in determining domination.\nlp_solver : Linear programming solver to be used internally. Pass a MathOptInterface.AbstractOptimizer type (such as HiGHS.Optimizer) if no option is needed, or a function (such as GameTheory.highs_optimizer_silent) to supply options.\n\nReturns\n\n::Bool : True if action is strictly dominated by some mixed action; false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.is_nash","page":"Base Types and Methods","title":"GameTheory.is_nash","text":"is_nash(g, action_profile; tol=1e-8)\n\nReturn true if action_profile is a Nash equilibrium.\n\nArguments\n\ng::NormalFormGame : Instance of N-player NormalFormGame.\naction_profile::ActionProfile : Tuple of N integers (pure actions) or N vectors of reals (mixed actions).\ntol::Real : Tolerance to be used to determine best response actions.\n\nReturns\n\n::Bool\n\n\n\n\n\n","category":"function"},{"location":"lib/base_types_and_methods.html#GameTheory.is_nash-Tuple{NormalFormGame{1}, Union{Integer, Vector{T}} where T<:Real}","page":"Base Types and Methods","title":"GameTheory.is_nash","text":"is_nash(g, action; tol=1e-8)\n\nReturn true if action is a Nash equilibrium of a trivial game with 1 player.\n\nArguments\n\ng::NormalFormGame{1} : Instance of 1-player NormalFormGame.\naction::Action : Integer (pure action) or vector of reals (mixed action).\ntol::Float64 : Tolerance to be used to determine best response actions.\n\nReturns\n\n::Bool\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.is_pareto_dominant","page":"Base Types and Methods","title":"GameTheory.is_pareto_dominant","text":"is_pareto_dominant(g, action_profile)\n\nReturn true if action_profile is Pareto dominant for game g.\n\nArguments\n\ng::NormalFormGame : Instance of N-player NormalFormGame.\naction_profile::PureActionProfile : Tuple of N integers (pure actions).\n\nReturns\n\n::Bool\n\n\n\n\n\n","category":"function"},{"location":"lib/base_types_and_methods.html#GameTheory.is_pareto_efficient","page":"Base Types and Methods","title":"GameTheory.is_pareto_efficient","text":"is_pareto_efficient(g, action_profile)\n\nReturn true if action_profile is Pareto efficient for game g.\n\nArguments\n\ng::NormalFormGame : Instance of N-player NormalFormGame.\naction_profile::PureActionProfile : Tuple of N integers (pure actions).\n\nReturns\n\n::Bool\n\n\n\n\n\n","category":"function"},{"location":"lib/base_types_and_methods.html#GameTheory.payoff_profile_array-Union{Tuple{NormalFormGame{N, T}}, Tuple{T}, Tuple{N}} where {N, T}","page":"Base Types and Methods","title":"GameTheory.payoff_profile_array","text":"payoff_profile_array(g)\n\nReturn an N-dimensional array of vectors, whose (a_1, ..., a_N)-entry contains a vector of N payoff values, one for each player, for the action profile (a_1, ..., a_N).\n\nArguments\n\ng::NormalFormGame : N-player NormalFormGame instance.\n\nReturns\n\n::Array{Vector,N} : Array of payoff profiles.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.payoff_vector-Tuple{Player, NTuple{N, T} where {N, T<:Integer}}","page":"Base Types and Methods","title":"GameTheory.payoff_vector","text":"payoff_vector(player, opponents_actions)\n\nReturn a vector of payoff values for a Player in an N>2 player game, one for each own action, given a tuple of the opponents' pure actions.\n\nArguments\n\nplayer::Player : Player instance.\nopponents_actions::PureActionProfile : Tuple of N-1 opponents' pure actions.\n\nReturns\n\n::Vector : Payoff vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.payoff_vector-Tuple{Player{1}, Nothing}","page":"Base Types and Methods","title":"GameTheory.payoff_vector","text":"payoff_vector(player, opponent_action)\n\nReturn a vector of payoff values for a Player in a trivial game with 1 player, one for each own action.\n\nArguments\n\nplayer::Player{1} : Player instance.\nopponent_action::Nothing\n\nReturns\n\n::Vector : Payoff vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.payoff_vector-Tuple{Player{2}, Integer}","page":"Base Types and Methods","title":"GameTheory.payoff_vector","text":"payoff_vector(player, opponent_action)\n\nReturn a vector of payoff values for a Player in a 2-player game, one for each own action, given the opponent's pure action.\n\nArguments\n\nplayer::Player{2} : Player instance.\nopponent_action::PureAction : Opponent's pure action (integer).\n\nReturns\n\n::Vector : Payoff vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.payoff_vector-Tuple{Player{2}, Vector{T} where T<:Real}","page":"Base Types and Methods","title":"GameTheory.payoff_vector","text":"payoff_vector(player, opponent_action)\n\nReturn a vector of payoff values for a Player in a 2-player game, one for each own action, given the opponent's mixed action.\n\nArguments\n\nplayer::Player{2} : Player instance.\nopponent_action::MixedAction : Opponent's mixed action (vector of reals).\n\nReturns\n\n::Vector : Payoff vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.payoff_vector-Union{Tuple{T2}, Tuple{T1}, Tuple{N2}, Tuple{N1}, Tuple{Player{N1, T1}, NTuple{N2, Vector{T2}}}} where {N1, N2, T1, T2}","page":"Base Types and Methods","title":"GameTheory.payoff_vector","text":"payoff_vector(player, opponents_actions)\n\nReturn a vector of payoff values for a Player in an N>2 player game, one for each own action, given a tuple of the opponents' mixed actions.\n\nArguments\n\nplayer::Player : Player instance.\nopponents_actions::MixedActionProfile : Tuple of N-1 opponents' mixed actions.\n\nReturns\n\n::Vector : Payoff vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#GameTheory.pure2mixed-Tuple{Integer, Integer}","page":"Base Types and Methods","title":"GameTheory.pure2mixed","text":"pure2mixed(num_actions, action)\n\nConvert a pure action to the corresponding mixed action.\n\nArguments\n\nnum_actions::Integer : The number of the pure actions (= the length of a mixed action).\naction::PureAction : The pure action to convert to the corresponding mixed action.\n\nReturns\n\nmixed_action::Vector{Float64} : The mixed action representation of the given pure action.\n\n\n\n\n\n","category":"method"},{"location":"lib/base_types_and_methods.html#Internal","page":"Base Types and Methods","title":"Internal","text":"","category":"section"},{"location":"lib/index.html#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"lib/index.html","page":"Index","title":"Index","text":"Modules = [GameTheory, GameTheory.Generators]","category":"page"},{"location":"lib/util.html#util","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"lib/util.html","page":"Utilities","title":"Utilities","text":"This is documentation for util.jl.","category":"page"},{"location":"lib/util.html#Exported","page":"Utilities","title":"Exported","text":"","category":"section"},{"location":"lib/util.html#Internal","page":"Utilities","title":"Internal","text":"","category":"section"},{"location":"lib/util.html#GameTheory.highs_optimizer_silent-Tuple{}","page":"Utilities","title":"GameTheory.highs_optimizer_silent","text":"highs_optimizer_silent()\n\nFunction that returns a HiGHS.Optimizer instance in silent mode.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#learning_algorithms","page":"Learning Algorithms","title":"Learning Algorithms","text":"","category":"section"},{"location":"lib/learning_algorithms.html#Exported","page":"Learning Algorithms","title":"Exported","text":"","category":"section"},{"location":"lib/learning_algorithms.html#GameTheory.AbstractBRD","page":"Learning Algorithms","title":"GameTheory.AbstractBRD","text":"AbstractBRD\n\nAbstract type representing the best response dynamics model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.BRD","page":"Learning Algorithms","title":"GameTheory.BRD","text":"BRD\n\nType representing the best response dynamics model.\n\nFields\n\nN::Int : The number of players.\nplayer::Player{2,T} : Player instance in the model.\nnum_actions::Int : The number of actions for players.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.BRD-Union{Tuple{T}, Tuple{Matrix{T}, Integer}} where T<:Real","page":"Learning Algorithms","title":"GameTheory.BRD","text":"BRD(N, payoff_array)\n\nCreate a new BRD instance.\n\nArguments\n\nN::Integer : The number of players.\npayoff_array::Matrix : Payoff array for each player.\n\nReturns\n\n::BRD : The best response dynamics model.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.KMR","page":"Learning Algorithms","title":"GameTheory.KMR","text":"KMR\n\nType representing the Kandori Mailath Rob model.\n\nFields\n\nN::Int : The number of players.\nplayer::Player : Player instance in the model.\nnum_actions::Int : The number of actions for players.\nepsilon::Float64 : The probability of strategy flips.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.KMR-Union{Tuple{T}, Tuple{Matrix{T}, Integer, Float64}} where T<:Real","page":"Learning Algorithms","title":"GameTheory.KMR","text":"KMR(N, payoff_array, epsilon)\n\nCreate a new KMR instance.\n\nArguments\n\nN::Integer : The number of players.\npayoff_array::Matrix : The payoff array for each player.\nepsilon::Float64 : The probability of strategy flips.\n\nReturns\n\n::KMR : The Kandori Mailath Rob model.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.SamplingBRD","page":"Learning Algorithms","title":"GameTheory.SamplingBRD","text":"SamplingBRD\n\nType representing the sampling best response dynamics model.\n\nFields\n\nN::Int : The number of players.\nplayer::Player : Player instance in the model.\nnum_actions::Int : The number of actions for players.\nk::Int : Sample size.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.SamplingBRD-Union{Tuple{T}, Tuple{Matrix{T}, Integer, Integer}} where T<:Real","page":"Learning Algorithms","title":"GameTheory.SamplingBRD","text":"SamplingBRD(N, payoff_array, k)\n\nCreate a new SamplingBRD instance.\n\nArguments\n\nN::Integer : The number of players.\npayoff_array::Matrix : Payoff array for a player.\nk::Integer : Sample size.\n\nReturns\n\n::SamplingBRD : The sampling best response dynamics model.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.play","page":"Learning Algorithms","title":"GameTheory.play","text":"play([rng=Random.GLOBAL_RNG, ]brd, init_action_dist[, options=BROptions(); num_reps=1])\n\nReturn the action distribution after num_reps times iteration\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nbrd::AbstractBRD : AbstractBRD instance.\ninit_action_dist::Vector{<:Integer} : The initial distribution of players' actions.\noptions::BROptions : Options for best_response method.\nnum_reps::Integer : The number of iterations.\n\nReturns\n\n::Vector{<:Integer} : The action distribution after iterations.\n\n\n\n\n\n","category":"function"},{"location":"lib/learning_algorithms.html#GameTheory.AbstractFictitiousPlay","page":"Learning Algorithms","title":"GameTheory.AbstractFictitiousPlay","text":"AbstractFictitiousPlay\n\nAbstract type representing a fictitious play model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.AbstractGain","page":"Learning Algorithms","title":"GameTheory.AbstractGain","text":"AbstractGain\n\nAbstract type representing the gain in a fictitious play model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.ConstantGain","page":"Learning Algorithms","title":"GameTheory.ConstantGain","text":"ConstantGain\n\nType representing a constant gain.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.DecreasingGain","page":"Learning Algorithms","title":"GameTheory.DecreasingGain","text":"DecreasingGain\n\nType representing a decresing gain.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.FictitiousPlay","page":"Learning Algorithms","title":"GameTheory.FictitiousPlay","text":"FictitiousPlay(g[, gain=DecreasingGain()])\n\nConstruct a FictitiousPlay instance from NormalFormGame.\n\nArguments\n\ng::NormalFormGame : NormalFormGame instance.\ngain::AbstractGain : Argument to specify the gain or step size; DecreasingGain() or ConstantGain(size).\n\nReturns\n\n::FictitiousPlay : The fictitious play model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.FictitiousPlay-2","page":"Learning Algorithms","title":"GameTheory.FictitiousPlay","text":"FictitiousPlay(fp[, gain=fp.gain])\n\nConstruct a new FictitiousPlay instance from fp.\n\nArguments\n\nfp::AbstractFictitiousPlay : AbstractFictitiousPlay instance.\ngain::AbstractGain : Argument to specify the gain or step size.\n\nReturns\n\n::FictitiousPlay : The fictitious play model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.FictitiousPlay-3","page":"Learning Algorithms","title":"GameTheory.FictitiousPlay","text":"FictitiousPlay{N, T, TG}\n\nType representing a fictitious play model with N players.\n\nFields\n\nplayers::NTuple{N,Player{N,T}} : Tuple of Player instances.\nnums_actions::NTuple{N,Int} : Tuple of the numbers of actions, one for each player.\ngain::TG<:AbstractGain : Gain type.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.StochasticFictitiousPlay","page":"Learning Algorithms","title":"GameTheory.StochasticFictitiousPlay","text":"StochasticFictitiousPlay(fp[, d=fp.d, gain=fp.gain])\n\nConstruct a new StochasticFictitiousPlay instance from fp.\n\nArguments\n\nfp::AbstractFictitiousPlay : AbstractFictitiousPlay instance.\nd::Distributions.Distribution : Distribution instance from which payoff perturbations are drawn.\ngain::AbstractGain : Argument to specify the gain or step size.\n\nReturns\n\n::StochasticFictitiousPlay : The stochastic fictitious play model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.StochasticFictitiousPlay-2","page":"Learning Algorithms","title":"GameTheory.StochasticFictitiousPlay","text":"StochasticFictitiousPlay(g, d[, gain=DecreasingGain()])\n\nConstruct a StochasticFictitiousPlay instance.\n\nArguments\n\ng::NormalFormGame : NormalFormGame instance.\nd::Distributions.Distribution : Distribution instance from which payoff perturbations are drawn.\ngain::AbstractGain : Argument to specify the gain or step size; DecreasingGain() or ConstantGain(size).\n\nReturns\n\n::StochasticFictitiousPlay : The stochastic fictitious play model.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.StochasticFictitiousPlay-3","page":"Learning Algorithms","title":"GameTheory.StochasticFictitiousPlay","text":"StochasticFictitiousPlay{N, T, TG, TD}\n\nType representing a stochastic fictitious play model with N players.\n\nFields\n\nplayers::NTuple{N,Player{N,T}} : Tuple of Player instances.\nnums_actions::NTuple{N,Int} : Tuple of the numbers of actions, one for each player.\ngain::TG<:AbstractGain : Gain type.\nd::TD<:Distributions.Distribution : Distribution instance from which payoff perturbations are drawn.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.AbstractRevision","page":"Learning Algorithms","title":"GameTheory.AbstractRevision","text":"AbstractRevision\n\nAbstract type representing revision method.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.AsynchronousRevision","page":"Learning Algorithms","title":"GameTheory.AsynchronousRevision","text":"AsynchronousRevision\n\nType representing an asynchronous revision.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.LocalInteraction","page":"Learning Algorithms","title":"GameTheory.LocalInteraction","text":"LocalInteraction{N, T, S, A, TR}\n\nType representing the local interaction model with N players.\n\nFields\n\nplayers::NTuple{N,Player{2,T}} : Tuple of Player instances.\nnum_actions::Integer : The number of actions for players.\nadj_matrix::Array{S,2} : Adjacency matrix of the graph in the model.\nrevision<:AbstractRevision : The way to revise the action profile.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.LocalInteraction-Union{Tuple{S}, Tuple{T}, Tuple{Matrix{T}, AbstractMatrix{S}}, Tuple{Matrix{T}, AbstractMatrix{S}, AbstractRevision}} where {T<:Real, S<:Real}","page":"Learning Algorithms","title":"GameTheory.LocalInteraction","text":"LocalInteraction(payoff_matrix,\n                 adj_matrix[, revision=SimultaneousRevision()])\n\nConstruct a LocalInteraction instance.\n\nArguments\n\npayoff_matrix::Matrix : The payoff matrix of the game.\nadj_matrix::AbstractMatrix : Adjacency matrix of the graph in the model.\nrevision::AbstractRevision : Arguments to specify the revision method. SimultaneousRevision() or AsynchronousRevision\n\nReturns\n\n::LocalInteraction : The local interaction model.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.LocalInteraction-Union{Tuple{S}, Tuple{T}, Tuple{NormalFormGame{2, T}, AbstractMatrix{S}}, Tuple{NormalFormGame{2, T}, AbstractMatrix{S}, AbstractRevision}} where {T<:Real, S<:Real}","page":"Learning Algorithms","title":"GameTheory.LocalInteraction","text":"LocalInteraction(g, adj_matrix[, revision=SimultaneousRevision()])\n\nConstruct a LocalInteraction instance.\n\nArguments\n\ng::NormalFormGame : The game used in the model.\nadj_matrix::AbstractMatrix : Adjacency matrix of the graph in the model.\nrevision::AbstractRevision : Arguments to specify the revision method; SimultaneousRevision() or AsynchronousRevision().\n\nReturns\n\n::LocalInteraction : The local interaction model.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.SimultaneousRevision","page":"Learning Algorithms","title":"GameTheory.SimultaneousRevision","text":"SimultaneousRevision\n\nType representing a simultaneous revision.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.LogitDynamics","page":"Learning Algorithms","title":"GameTheory.LogitDynamics","text":"LogitDynamics{N, T, S}\n\nType representing the Logit-Dynamics model.\n\nFields\n\nplayers::NTuple{N,Player{N,T}} : Tuple of Player instances.\nnums_actions::NTuple{N,Int} : Tuple of the numbers of actions, one for each player.\nbeta<:Real : The level of noise in a player's decision.\nchoice_probs::Vector{Array} : The choice probabilities of each action, one for each player.\n\n\n\n\n\n","category":"type"},{"location":"lib/learning_algorithms.html#GameTheory.LogitDynamics-Union{Tuple{S}, Tuple{T}, Tuple{N}, Tuple{NormalFormGame{N, T}, S}} where {N, T<:Real, S<:Real}","page":"Learning Algorithms","title":"GameTheory.LogitDynamics","text":"LogitDynamics(g, beta)\n\nConstruct a LogitDynamics instance.\n\nArguments\n\ng::NormalFormGame{N,T} : NormalFormGame instance.\nbeta::S : The level of noise in players' decision.\n\nReturns\n\n::LogitDynamics : The Logit-Dynamics model.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.play!-Union{Tuple{N}, Tuple{Random.AbstractRNG, LogitDynamics{N}, Integer, Vector{<:Integer}}} where N","page":"Learning Algorithms","title":"GameTheory.play!","text":"play!(rng, ld, player_ind, actions)\n\nReturn a new action of player indexed by player_ind given each players' choice probabilities.\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nld::LogitDynamics{N} : LogitDynamics instance.\nplayer_ind::Integer : A player index who takes an action.\nactions::Vector{<:Integer} : The action profile.\n\nReturns\n\n::Integer : The new action of the player indexed by player_ind.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.play-Union{Tuple{N}, Tuple{Random.AbstractRNG, LogitDynamics{N}, NTuple{N, T} where {N, T<:Integer}}} where N","page":"Learning Algorithms","title":"GameTheory.play","text":"play([rng=Random.GLOBAL_RNG,] ld, init_actions[; num_reps=1])\n\nReturn new action profile after num_reps iterations.\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nld::LogitDynamics{N} : LogitDynamics instance.\ninit_actions::PureActionProfile : Initial action profile.\nnum_reps::Integer : The number of iterations.\n\nReturns\n\n::Vector{<:Integer} : New action profile.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.time_series-Union{Tuple{N}, Tuple{Random.AbstractRNG, LogitDynamics{N}, Integer, NTuple{N, T} where {N, T<:Integer}}} where N","page":"Learning Algorithms","title":"GameTheory.time_series","text":"time_series([rng=Random.GLOBAL_RNG,] ld, ts_length, init_actions)\n\nReturn a time series of action profiles.\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nld::LogitDynamics{N} : LogitDynamics instance.\nts_length::Integer : The length of time series.\ninit_actions::PureActionProfile : Initial action profile.\n\nReturns\n\n::Matrix{<:Integer} : The time series of action profiles.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#Internal","page":"Learning Algorithms","title":"Internal","text":"","category":"section"},{"location":"lib/learning_algorithms.html#GameTheory.time_series!-Tuple{Random.AbstractRNG, AbstractBRD, Matrix{<:Integer}, Vector{<:Integer}, BROptions}","page":"Learning Algorithms","title":"GameTheory.time_series!","text":"time_series!(rng, brd, out, player_ind_seq, options)\n\nUpdate the matrix out which is used in time_series method given a player index sequence.\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nbrd::AbstractBRD : Instance of the model.\nout::Matrix{<:Integer} : Matrix representing the time series of action profiles.\nplayer_ind_seq::Vector{<:Integer} : The vector of player index.\noptions::BROptions : Options for best_response method.\n\nReturns\n\nout::Matrix{<:Integer} : Updated out.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.time_series!-Union{Tuple{N}, Tuple{Random.AbstractRNG, AbstractFictitiousPlay{N}, NTuple{N, Matrix{<:Real}}}, Tuple{Random.AbstractRNG, AbstractFictitiousPlay{N}, NTuple{N, Matrix{<:Real}}, BROptions}} where N","page":"Learning Algorithms","title":"GameTheory.time_series!","text":"time_series!(rng, fp, out[, options=BROptions(); t_init=1])\n\nUpdate the tuple of matrices out which is used in time_series method.\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nfp::AbstractFictitiousPlay{N} : AbstractFictitiousPlay instance.\nout::NTuple{N,Matrix{<:Real}} : Tuple of matrices which represent the time   series of mixed action profile.\noptions::BROptions : Options for best_response.\nt_init::Integer : The period when the iteration starts.\n\nReturns\n\nout::NTuple{N,Matrix{<:Real}} : Updated out.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.time_series!-Union{Tuple{N}, Tuple{LocalInteraction{N}, Matrix{<:Integer}, BROptions, Vector{<:Integer}}} where N","page":"Learning Algorithms","title":"GameTheory.time_series!","text":"time_series!(li, out, options, player_ind_seq)\n\nUpdate the matrix out which is used in time_series method given player index sequence.\n\nArguments\n\nli::LocalInteraction{N} : LocalInteraction instance.\nout::Matrix{<:Integer} : Matrix representing a time series of action profiles.\noptions::BROptions : Options for best_response method.\nplayer_ind_seq::Vector{<:Integer} : Vector representing the index of players to take an action.\n\nReturns\n\nout::Matrix{<:Integer} : Updated out.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.time_series!-Union{Tuple{N}, Tuple{LocalInteraction{N}, Matrix{<:Integer}, BROptions}} where N","page":"Learning Algorithms","title":"GameTheory.time_series!","text":"time_series!(li, out, options)\n\nUpdate the matrix out which is used in time_series method. All players take their actions simultaneously.\n\nArguments\n\nli::LocalInteraction{N} : LocalInteraction instance.\nout::Matrix{<:Integer} : Matrix representing a time series of action profiles.\noptions::BROptions : Options for best_response method.\n\nReturns\n\nout::Matrix{<:Integer} : Updated out.\n\n\n\n\n\n","category":"method"},{"location":"lib/learning_algorithms.html#GameTheory.time_series!-Union{Tuple{N}, Tuple{Random.AbstractRNG, LogitDynamics{N}, Matrix{<:Integer}, Vector{<:Integer}}} where N","page":"Learning Algorithms","title":"GameTheory.time_series!","text":"time_series!(rng, ld, out, player_ind_seq)\n\nUpdate the matrix out which is used in time_series method given a player index sequence.\n\nArguments\n\nrng::AbstractRNG : Random number generator used.\nld::LogitDynamics{N} : LogitDynamics instance.\nout::Matrix{<:Integer} : Matrix representing the time series of action profiles.\nplayer_ind_seq::Vector{<:Integer} : The sequence of player index, which is determined randomly.\n\nReturns\n\n::Matrix{<:Integer} : Updated out.\n\n\n\n\n\n","category":"method"},{"location":"index.html#GameTheory.jl","page":"Home","title":"GameTheory.jl","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"GameTheory.jl is a Julia package about algorithms and data structures for Game Theory.","category":"page"},{"location":"index.html#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"To install the package, enter the Pkg mode by pressing ] and run","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"add GameTheory","category":"page"},{"location":"index.html#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Once installed, the GameTheory package can be used by typing","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"using GameTheory","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The Base type Player can be created by passing a payoff matrix:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"player1 = Player([3 1; 0 2])","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"A 2-player NormalFormGame can be created either by passing Player instances,","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"player2 = Player([2 0; 1 3])\ng = NormalFormGame((player1, player2))\nprint(g)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"or by passing a payoff matrix directly:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"payoff_bimatrix = Array{Int}(undef, 2, 2, 2)\npayoff_bimatrix[1, 1, :] = [3, 2]\npayoff_bimatrix[1, 2, :] = [1, 1]\npayoff_bimatrix[2, 1, :] = [0, 0]\npayoff_bimatrix[2, 2, :] = [2, 3]\ng = NormalFormGame(payoff_bimatrix)\nprint(g)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"After constructing a NormalFormGame, we can find its Nash Equilibria by using methods of GameTheory. For example, pure_nash finds all pure action Nash Equilibria by enumeration:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"pure_nash(g)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"Please see the notebooks on QuantEcon for more details.","category":"page"},{"location":"index.html#notebooks","page":"Home","title":"Notebooks","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Some notebooks for demonstration are available:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"Tools for Game Theory\nA Recursive Formulation of Repeated Games","category":"page"},{"location":"index.html#Library-Outline","page":"Home","title":"Library Outline","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Base Types and Methods\nGame Generators\nComputing Nash Equilibria\nLearning Algorithms\nRepeated Games\nUtilities","category":"page"},{"location":"lib/repeated_games.html#repeated_games","page":"Repeated Games","title":"Repeated Games","text":"","category":"section"},{"location":"lib/repeated_games.html#Exported","page":"Repeated Games","title":"Exported","text":"","category":"section"},{"location":"lib/repeated_games.html#GameTheory.RepeatedGame","page":"Repeated Games","title":"GameTheory.RepeatedGame","text":"RepeatedGame{N,T}\n\nType representing an N-player repeated game.\n\nFields\n\nsg::NormalFormGame{N, T} : The stage game used to create the repeated game.\ndelta::Float64 : The common discount rate at which all players discount the future.\n\n\n\n\n\n","category":"type"},{"location":"lib/repeated_games.html#GameTheory.RepeatedGame-Tuple{Player, Player, Float64}","page":"Repeated Games","title":"GameTheory.RepeatedGame","text":"RepeatedGame(p1, p2, delta)\n\nHelper constructor that builds a repeated game for two players.\n\nArguments\n\np1::Player : The first player.\np2::Player : The second player.\ndelta::Float64 : The common discount rate at which all players discount the future.\n\nReturns\n\n::RepeatedGame : The repeated game.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.AS-Union{Tuple{RepeatedGame{2}}, Tuple{TU}} where TU","page":"Repeated Games","title":"GameTheory.AS","text":"AS(rpd; maxiter=1000, plib=default_library(2, Float64), tol=1e-5, u=nothing)\n\nUsing AS algorithm to compute the set of payoff pairs of all pure-strategy subgame-perfect equilibria with public randomization for any repeated two-player games with perfect monitoring and discounting, following Abreu and Sannikov (2014).\n\nArguments\n\nrpd::RepeatedGame{2, T} : Two player repeated game with T<:Real.\nmaxiter::Integer : Maximum number of iterations.\nplib: Allows users to choose a particular package for the geometry computations. (See Polyhedra.jl docs for more info). By default, it chooses to use SimplePolyhedraLibrary.\ntol::Float64 : Tolerance in differences of set.\nu : The punishment payoff pair if any player deviates. In default, we use minimax payoff pair. If there is better guess, you can specify it by passing a Vector with length 2.\n\nReturns\n\n::Matrix{T} : Vertices of the set of payoff pairs.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.outerapproximation-Tuple{RepeatedGame{2}}","page":"Repeated Games","title":"GameTheory.outerapproximation","text":"outerapproximation(rpd; nH=32, tol=1e-8, maxiter=500, check_pure_nash=true,\n                   verbose=false, nskipprint=50,\n                   plib=CDDLib.Library(),\n                   lp_solver=GameTheory.highs_optimizer_silent)\n\nApproximates the set of equilibrium values for a repeated game with the outer hyperplane approximation described by Judd, Yeltekin, Conklin (2002).\n\nArguments\n\nrpd::RepGame2 : Two player repeated game.\nnH::Int : Number of subgradients used for the approximation.\ntol::Float64 : Tolerance in differences of set.\nmaxiter::Int : Maximum number of iterations.\ncheck_pure_nash: Whether to perform a check about whether a pure Nash equilibrium exists.\nverbose::Bool : Whether to display updates about iterations and distance.\nnskipprint::Int : Number of iterations between printing information (assuming verbose=true).\nplib::Polyhedra.Library: Allows users to choose a particular package for the geometry computations. (See Polyhedra.jl docs for more info). By default, it chooses to use CDDLib.Library().\nlp_solver : Linear programming solver to be used internally. Pass a MathOptInterface.AbstractOptimizer type (such as HiGHS.Optimizer) if no option is needed, or a function (such as GameTheory.highs_optimizer_silent) to supply options.\n\nReturns\n\nvertices::Matrix{Float64} : Vertices of the outer approximation of the value set.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.unpack-Tuple{RepeatedGame}","page":"Repeated Games","title":"GameTheory.unpack","text":"unpack(rpd)\n\nHelper function that unpacks the elements of a repeated game.\n\nArguments\n\nrpd::RepeatedGame : The repeated game.\n\nReturns\n\n::Tuple{NormalFormGame, Float64} : A tuple containing the stage game and the delta.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.worst_value_1","page":"Repeated Games","title":"GameTheory.worst_value_1","text":"See worst_value_i for documentation\n\n\n\n\n\n","category":"function"},{"location":"lib/repeated_games.html#GameTheory.worst_value_2","page":"Repeated Games","title":"GameTheory.worst_value_2","text":"See worst_value_i for documentation\n\n\n\n\n\n","category":"function"},{"location":"lib/repeated_games.html#GameTheory.worst_value_i","page":"Repeated Games","title":"GameTheory.worst_value_i","text":"worst_value_i(rpd, H, C, i, lp_solver=highs_optimizer_silent)\n\nGiven a constraint w ∈ W, this finds the worst possible payoff for agent i.\n\nArguments\n\nrpd::RepGame2 : Two player repeated game.\nH::Matrix{Float64} : Matrix of shape (nH, 2) containing the subgradients here nH is the number of subgradients.\nC::Vector{Float64} : The array containing the hyperplane levels.\ni::Int : The player of interest.\nlp_solver : Linear programming solver to be used internally. Pass a MathOptInterface.AbstractOptimizer type (such as HiGHS.Optimizer) if no option is needed, or a function (such as GameTheory.highs_optimizer_silent) to supply options.\n\nReturns\n\nout::Float64 : Worst possible payoff for player i.\n\n\n\n\n\n","category":"function"},{"location":"lib/repeated_games.html#Internal","page":"Repeated Games","title":"Internal","text":"","category":"section"},{"location":"lib/repeated_games.html#GameTheory.RepGame2","page":"Repeated Games","title":"GameTheory.RepGame2","text":"RepGame2\n\nType representing a 2-player repeated game; alias for RepeatedGame{2}.\n\n\n\n\n\n","category":"type"},{"location":"lib/repeated_games.html#GameTheory._best_dev_gains-Union{Tuple{NormalFormGame{2, T}}, Tuple{T}} where T","page":"Repeated Games","title":"GameTheory._best_dev_gains","text":"_best_dev_gains(g)\n\nCalculate the payoff gains from deviating from the current action to the best response for each player.\n\nArguments\n\ng::NormalFormGame{2, T} : Two-player NormalFormGame.\n\nReturns\n\n::Tuple{Matrix{T}, Matrix{T}} : Tuple of best deviating gain matrices for two players. For example, for the first matrix best_dev_gains1, best_dev_gains1[i, j] is the payoff gain for player 1 for deviating to the best response from ith action given player 2 choosing jth action.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory._payoff_points-Union{Tuple{T}, Tuple{Type{T}, NormalFormGame{2}}} where T","page":"Repeated Games","title":"GameTheory._payoff_points","text":"_payoff_points(::Type{T}, g)\n\nReturn a matrix with each row being a payoff pair point in the two dimensional space.\n\nArguments\n\ng::NormalFormGame{2} : Two-player NormalFormGame.\n\nReturns\n\nv::Matrix{T} : Matrix with size n by 2, where n is the number of action profiles. Each row corresponds to one payoff pair.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.initialize_LP_matrices-Tuple{RepeatedGame{2}, Matrix{Float64}}","page":"Repeated Games","title":"GameTheory.initialize_LP_matrices","text":"initialize_LP_matrices(rpd, H)\n\nInitialize matrices for the linear programming problems.\n\nArguments\n\nrpd::RepeatedGame : Two player repeated game.\nH::Matrix{Float64} : Matrix of shape (nH, 2) containing the subgradients used to approximate the value set, where nH is the number of subgradients.\n\nReturns\n\nc::Vector{Float64} : Vector of length nH used to determine which subgradient should be used, where nH is the number of subgradients.\nA::Matrix{Float64} : Matrix of shape (nH+2, 2) with nH set constraints and to be filled with 2 additional incentive compatibility constraints.\nb::Vector{Float64} : Vector of length nH+2 to be filled with the values for the constraints.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.initialize_sg_hpl-Tuple{Int64, Vector{Float64}, Float64}","page":"Repeated Games","title":"GameTheory.initialize_sg_hpl","text":"initialize_sg_hpl(nH, o, r)\n\nInitializes subgradients, extreme points and hyperplane levels for the approximation of the convex value set of a 2 player repeated game.\n\nArguments\n\nnH::Int : Number of subgradients used for the approximation.\no::Vector{Float64} : Origin for the approximation.\nr::Float64 : Radius for the approximation.\n\nReturns\n\nC::Vector{Float64} : Vector of length nH containing the hyperplane levels.\nH::Matrix{Float64} : Matrix of shape (nH, 2) containing the subgradients.\nZ::Matrix{Float64} : Matrix of shape (nH, 2) containing the extreme points of the value set.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.initialize_sg_hpl-Tuple{RepeatedGame, Int64}","page":"Repeated Games","title":"GameTheory.initialize_sg_hpl","text":"initialize_sg_hpl(rpd, nH)\n\nInitializes subgradients, extreme points and hyperplane levels for the approximation of the convex value set of a 2 player repeated game by choosing an appropriate origin and radius.\n\nArguments\n\nrpd::RepeatedGame : Two player repeated game.\nnH::Int : Number of subgradients used for the approximation.\n\nReturns\n\nC::Vector{Float64} : Vector of length nH containing the hyperplane levels.\nH::Matrix{Float64} : Matrix of shape (nH, 2) containing the subgradients.\nZ::Matrix{Float64} : Matrix of shape (nH, 2) containing the extreme points of the value set.\n\n\n\n\n\n","category":"method"},{"location":"lib/repeated_games.html#GameTheory.unitcircle-Tuple{Int64}","page":"Repeated Games","title":"GameTheory.unitcircle","text":"unitcircle(npts)\n\nPlaces npts equally spaced points along the 2 dimensional unit circle and returns the points with x coordinates in first column and y coordinates in second column.\n\nArguments\n\nnpts::Int : Number of points to be placed.\n\nReturns\n\npts::Matrix{Float64} : Matrix of shape (nH, 2) containing the coordinates of the points.\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#game_generators","page":"Game Generators","title":"Game Generators","text":"","category":"section"},{"location":"lib/game_generators.html#Exported","page":"Game Generators","title":"Exported","text":"","category":"section"},{"location":"lib/game_generators.html#GameTheory.covariance_game-Union{Tuple{N}, Tuple{Random.AbstractRNG, NTuple{N, Int64}, Real}} where N","page":"Game Generators","title":"GameTheory.covariance_game","text":"covariance_game([rng=GLOBAL_RNG], nums_actions, rho)\n\nReturn a random N-player NormalFormGame instance with N>=2 where the payoff profiles are drawn independently from the standard multi-normal with the covariance of any pair of payoffs equal to rho, as studied in Rinott and Scarsini (2000).\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nnums_actions::NTuple{N,Int}: Tuple of the numbers of actions, one for each player.\nrho::Real: Covariance of a pair of payoff values. Must be in [-1/(N-1), 1], where N is the number of players.\n\nReturns\n\n::NormalFormGame: The generated random N-player NormalFormGame.\n\nExamples\n\njulia> using GameTheory, Random\n\njulia> rng = MersenneTwister(12345);\n\njulia> g = covariance_game(rng, (4, 3), -0.7);\n\njulia> println(g)\n4×3 NormalFormGame{2, Float64}:\n [1.17236, -0.211696]   [1.46647, -1.13947]    [0.378353, 0.603951]\n [0.415565, 0.0779055]  [0.606808, 1.00812]    [1.12871, -1.03399]\n [0.685759, -0.278449]  [-0.588508, 0.464548]  [-0.970332, -0.0319236]\n [-1.47708, 1.12447]    [1.92585, -2.27959]    [-2.1476, 1.53569]\n\nReferences\n\nY. Rinott and M. Scarsini, \"On the Number of Pure Strategy Nash Equilibria in Random Games,\" Games and Economic Behavior (2000), 274-293.\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#GameTheory.random_game-Union{Tuple{T}, Tuple{N}, Tuple{Random.AbstractRNG, Union{AbstractRange{T}, Type{T}}, NTuple{N, Int64}}} where {N, T<:Real}","page":"Game Generators","title":"GameTheory.random_game","text":"random_game([rng=GLOBAL_RNG], [S=Float64], nums_actions)\n\nReturn a random N-player NormalFormGame instance where the payoffs are drawn independently from the uniform distribution on the set as determined by S. S is a range (such as 0:9) or a subtype of Integer or AbstractFloat; in the latter case, the set is [0, 1) for floats and typemin(S):typemax(S) for integers.\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nS::Union{Type,AbstractRange}: Set of values from which payoffs are drawn.\nnums_actions::NTuple{N,Int}: Tuple of the numbers of actions, one for each player.\n\nReturns\n\n::NormalFormGame: The generated random N-player NormalFormGame.\n\nExamples\n\njulia> using GameTheory, Random\n\njulia> rng = MersenneTwister(12345);\n\njulia> g = random_game(rng, (4, 3));\n\njulia> println(g)\n4×3 NormalFormGame{2, Float64}:\n [0.562714, 0.586598]  [0.381128, 0.0501668]  [0.922317, 0.61179]\n [0.849939, 0.620099]  [0.365801, 0.215712]   [0.0404417, 0.569955]\n [0.371605, 0.965631]  [0.835014, 0.364706]   [0.573382, 0.923602]\n [0.283365, 0.754047]  [0.260024, 0.696476]   [0.981364, 0.0311643]\n\njulia> g = random_game(rng, 0:9, (4, 3));\n\njulia> println(g)\n4×3 NormalFormGame{2, Int64}:\n [1, 5]  [1, 2]  [6, 2]\n [2, 5]  [0, 2]  [1, 0]\n [0, 5]  [3, 9]  [1, 1]\n [9, 5]  [2, 9]  [0, 6]\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#GameTheory.random_mixed_actions-Union{Tuple{N}, Tuple{Random.AbstractRNG, NTuple{N, Int64}}} where N","page":"Game Generators","title":"GameTheory.random_mixed_actions","text":"random_mixed_actions([rng=GLOBAL_RNG], nums_actions)\n\nReturn a tuple of random mixed actions (vectors of floats).\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nnums_actions::NTuple{N,Int}: N-tuple of the numbers of actions, one for each player.\n\nReturns\n\n::NTuple{N,Vector{Float64}}: N-tuple of random mixed actions.\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#GameTheory.random_pure_actions-Union{Tuple{N}, Tuple{Random.AbstractRNG, NTuple{N, Int64}}} where N","page":"Game Generators","title":"GameTheory.random_pure_actions","text":"random_pure_actions([rng=GLOBAL_RNG], nums_actions)\n\nReturn a tuple of random pure actions (integers).\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nnums_actions::NTuple{N,Int}: N-tuple of the numbers of actions, one for each player.\n\nReturns\n\n::NTuple{N,Int}: N-tuple of random pure actions.\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#GameTheory.Generators.blotto_game","page":"Game Generators","title":"GameTheory.Generators.blotto_game","text":"blotto_game([rng=GLOBAL_RNG], h, t, rho[, mu=0])\n\nReturn a NormalFormGame instance of a 2-player non-zero sum Colonel Blotto game (Hortala-Vallve and Llorente-Saguer, 2012), where the players have an equal number t of troops to assign to h hills (so that the number of actions for each player is equal to (t+h-1) choose (h-1) = (T+h-1)!/(T!*(h-1)!)). Each player has a value for each hill that he receives if he assigns strictly more troops to the hill than his opponent (ties are broken uniformly at random), where the values are drawn from a multivariate normal distribution with covariance rho. Each player’s payoff is the sum of the values of the hills won by that player.\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nh::Integer : Number of hills.\nt::Integer : Number of troops.\nrho::Real : Covariance of the players' values of each hill. Must be in [-1, 1].\nmu::Real=0 : Mean of the players' values of each hill.\n\nReturns\n\ng::NormalFormGame\n\nExamples\n\njulia> using GameTheory.Generators, Random\n\njulia> rng = MersenneTwister(1234);\n\njulia> g = blotto_game(rng, 2, 3, 0.5)\n4×4 NormalFormGame{2, Float64}\n\njulia> g.players[1]\n4×4 Player{2, Float64}:\n 0.186434  -0.494479  -0.494479  -0.494479\n 0.867347   0.186434  -0.494479  -0.494479\n 0.867347   0.867347   0.186434  -0.494479\n 0.867347   0.867347   0.867347   0.186434\n\njulia> g.players[2]\n4×4 Player{2, Float64}:\n -0.688223  -1.02919   -1.02919   -1.02919\n -0.347259  -0.688223  -1.02919   -1.02919\n -0.347259  -0.347259  -0.688223  -1.02919\n -0.347259  -0.347259  -0.347259  -0.688223\n\n\n\n\n\n","category":"function"},{"location":"lib/game_generators.html#GameTheory.Generators.ranking_game","page":"Game Generators","title":"GameTheory.Generators.ranking_game","text":"ranking_game([rng=GLOBAL_RNG], n[, steps=10])\n\nReturn a NormalFormGame instance of (the 2-player version of) the \"ranking game\" studied by Goldberg et al. (2013), where each player chooses an effort level associated with a score and a cost which are both increasing functions with randomly generated step sizes. The player with the higher score wins the first prize, whose value is 1, and the other player obtains the \"second prize\" of value 0; in the case of a tie, the first prize is split and each player receives a value of 0.5. The payoff of a player is given by the value of the prize minus the cost of the effort.\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nn::Integer : Number of actions, i.e, number of possible effort levels.\nsteps::Integer=10 : Parameter determining the upper bound for the size of the random steps for the scores and costs for each player: The step sizes for the scores are drawn from 1, ..., steps, while those for the costs are multiples of 1/(n*steps), where the cost of effort level 1 is 0, and the maximum possible cost of effort level n is less than or equal to 1.\n\nReturns\n\ng::NormalFormGame\n\nExamples\n\njulia> using GameTheory.Generators, Random\n\njulia> rng = MersenneTwister(1234);\n\njulia> g = ranking_game(rng, 5)\n5×5 NormalFormGame{2, Float64}\n\njulia> g.players[1]\n5×5 Player{2, Float64}:\n 0.5    0.0    0.0    0.0    0.0\n 0.92  -0.08  -0.08  -0.08  -0.08\n 0.88   0.88   0.88   0.88  -0.12\n 0.74   0.74   0.74   0.74   0.74\n 0.58   0.58   0.58   0.58   0.58\n\njulia> g.players[2]\n5×5 Player{2, Float64}:\n 0.5   0.0    0.0    0.0    0.0\n 0.92  0.92  -0.08  -0.08  -0.08\n 0.76  0.76  -0.24  -0.24  -0.24\n 0.56  0.56  -0.44  -0.44  -0.44\n 0.44  0.44   0.44  -0.56  -0.56\n\n\n\n\n\n","category":"function"},{"location":"lib/game_generators.html#GameTheory.Generators.sgc_game-Tuple{Integer}","page":"Game Generators","title":"GameTheory.Generators.sgc_game","text":"sgc_game(k)\n\nReturn a NormalFormGame instance of the 2-player game introduced by Sandholm, Gilpin, and Conitzer (2005), which has a unique Nash equilibrium, where each player plays half of the actions with positive probabilities. Payoffs are normalized so that the minimum and the maximum payoffs are 0 and 1, respectively.\n\nArguments\n\nk::Integer : Positive integer determining the number of actions. The returned game will have 4*k-1 actions for each player.\n\nReturns\n\ng::NormalFormGame\n\nExamples\n\njulia> using GameTheory.Generators\n\njulia> g = sgc_game(2)\n7×7 NormalFormGame{2, Float64}\n\njulia> g.players[1]\n7×7 Player{2, Float64}:\n 0.75  0.5   1.0   0.5   0.5   0.5   0.5\n 1.0   0.75  0.5   0.5   0.5   0.5   0.5\n 0.5   1.0   0.75  0.5   0.5   0.5   0.5\n 0.0   0.0   0.0   0.75  0.0   0.0   0.0\n 0.0   0.0   0.0   0.0   0.75  0.0   0.0\n 0.0   0.0   0.0   0.0   0.0   0.75  0.0\n 0.0   0.0   0.0   0.0   0.0   0.0   0.75\n\njulia> g.players[2]\n7×7 Player{2, Float64}:\n 0.75  0.5   1.0   0.5   0.5   0.5   0.5\n 1.0   0.75  0.5   0.5   0.5   0.5   0.5\n 0.5   1.0   0.75  0.5   0.5   0.5   0.5\n 0.0   0.0   0.0   0.0   0.75  0.0   0.0\n 0.0   0.0   0.0   0.75  0.0   0.0   0.0\n 0.0   0.0   0.0   0.0   0.0   0.0   0.75\n 0.0   0.0   0.0   0.0   0.0   0.75  0.0\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#GameTheory.Generators.tournament_game-Tuple{Random.AbstractRNG, Integer, Integer}","page":"Game Generators","title":"GameTheory.Generators.tournament_game","text":"tournament_game([rng=GLOBAL_RNG], n, k)\n\nReturn a NormalFormGame instance of the 2-player win-lose game, whose payoffs are either 0 or 1, introduced by Anbalagan et al. (2013). Player 1 has n actions, which constitute the set of nodes {1, ..., n}, while player 2 has n choose k actions, each corresponding to a subset of k elements of the set of n nodes. Given a randomly generated tournament graph on the n nodes, the payoff for player 1 is 1 if, in the tournament, the node chosen by player 1 dominates all the nodes in the k-subset chosen by player 2. The payoff for player 2 is 1 if player 2's k-subset contains player 1's chosen node.\n\nNotes\n\nThe actions of player 2 are ordered according to the combinatorial number system, which is different from the order used in the original library in C.\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nn::Integer : Number of nodes in the tournament graph.\nk::Integer : Size of subsets of nodes in the tournament graph.\n\nReturns\n\ng::NormalFormGame\n\nExamples\n\njulia> using GameTheory.Generators, Random\n\njulia> rng = MersenneTwister(1234);\n\njulia> g = tournament_game(rng, 5, 2)\n5×10 NormalFormGame{2, Float64}\n\njulia> g.players[1]\n5×10 Player{2, Float64}:\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n\njulia> g.players[2]\n10×5 Player{2, Float64}:\n 1.0  1.0  0.0  0.0  0.0\n 1.0  0.0  1.0  0.0  0.0\n 0.0  1.0  1.0  0.0  0.0\n 1.0  0.0  0.0  1.0  0.0\n 0.0  1.0  0.0  1.0  0.0\n 0.0  0.0  1.0  1.0  0.0\n 1.0  0.0  0.0  0.0  1.0\n 0.0  1.0  0.0  0.0  1.0\n 0.0  0.0  1.0  0.0  1.0\n 0.0  0.0  0.0  1.0  1.0\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#GameTheory.Generators.unit_vector_game-Tuple{Random.AbstractRNG, Integer}","page":"Game Generators","title":"GameTheory.Generators.unit_vector_game","text":"unit_vector_game([rng=GLOBAL_RNG], n; avoid_pure_nash=false)\n\nReturn a NormalFormGame instance of the 2-player game \"unit vector game\" (Savani and von Stengel, 2016). Payoffs for player 2 are chosen randomly from the [0, 1) range. For player 1, each column contains exactly one 1 payoff and the rest is\n\n\n\nArguments\n\nrng::AbstractRNG=GLOBAL_RNG: Random number generator used.\nn::Integer : Number of actions.\navoid_pure_nash::Bool=false : If true, player 1's payoffs will be placed in order to avoid pure Nash equilibria. (If necessary, the payoffs for player 2 are redrawn so as not to have a dominant action.)\n\nReturns\n\ng::NormalFormGame\n\nExamples\n\njulia> using GameTheory.Generators, Random\n\njulia> rng = MersenneTwister(123456);\n\njulia> g = unit_vector_game(rng, 5)\n5×5 NormalFormGame{2, Float64}\n\njulia> g.players[1]\n5×5 Player{2, Float64}:\n 0.0  0.0  0.0  0.0  0.0\n 1.0  0.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0\n 0.0  1.0  0.0  1.0  0.0\n\njulia> g.players[2]\n5×5 Player{2, Float64}:\n 0.51521   0.574332    0.391494   0.316183  0.913325\n 0.74129   0.47338     0.0110828  0.986807  0.302641\n 0.582142  0.635053    0.7289     0.324831  0.240347\n 0.209969  0.00394602  0.588569   0.627509  0.692993\n 0.180649  0.998717    0.0955464  0.974204  0.994846\n\njulia> pure_nash(g)\n1-element Vector{Tuple{Int64, Int64}}:\n (2, 5)\n\nWith avoid_pure_nash=true:\n\njulia> rng = MersenneTwister(123456);\n\njulia> g = unit_vector_game(rng, 5; avoid_pure_nash=true)\n5×5 NormalFormGame{2, Float64}\n\njulia> g.players[1]\n5×5 Player{2, Float64}:\n 0.0  0.0  0.0  0.0  0.0\n 1.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0\n 0.0  0.0  1.0  0.0  0.0\n 0.0  1.0  0.0  1.0  0.0\n\njulia> g.players[2]\n5×5 Player{2, Float64}:\n 0.51521   0.574332    0.391494   0.316183  0.913325\n 0.74129   0.47338     0.0110828  0.986807  0.302641\n 0.582142  0.635053    0.7289     0.324831  0.240347\n 0.209969  0.00394602  0.588569   0.627509  0.692993\n 0.180649  0.998717    0.0955464  0.974204  0.994846\n\njulia> pure_nash(g)\nTuple{Int64, Int64}[]\n\n\n\n\n\n","category":"method"},{"location":"lib/game_generators.html#Internal","page":"Game Generators","title":"Internal","text":"","category":"section"}]
}
